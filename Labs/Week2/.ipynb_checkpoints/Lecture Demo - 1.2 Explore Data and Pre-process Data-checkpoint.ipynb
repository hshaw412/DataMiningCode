{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2. Data Exploration and Pre-processing\n",
    "Load wine data from UCI data repositories and show some samples with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv' , sep = ';')\n",
    "df.head()          # import and display the first five rows of wine data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore data statisitcal information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "print(df.isnull().any()) # check if the data has Null values (noisy), missing value check, quite clean  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use describe() function to see all statistical information of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame.hist(df, figsize = [15,15]);\n",
    "pd.DataFrame.boxplot(df, figsize = [15,15]);   \n",
    "\n",
    "# draw the boxplot based on each attribute\n",
    "# Outlier: usually, a value higher than Q3+1.5xIQR or lower than Q1-1.5xIQR.  IQR=(Q3-Q1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.boxplot(['alcohol','quality'])   # boxplot on the specified attributes: alcohol and quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(['pH'])     # boxplot on the specified attribute: PH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.hist(df,figsize=[15,15])     # draw histogram for all the 12 attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From histograms and boxplots, can you see some outliers?  \n",
    "\n",
    "Outside the majority range could be outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "d1 = np.array(df.iloc[0], dtype=np.float32)\n",
    "d2 = np.array(df.iloc[1], dtype=np.float32)\n",
    "print(d1)           # display the first row of wine data\n",
    "print(d2)           # display the second row of wine data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to computer Manhattan Distance and Euclidean Distance? <br>\n",
    "Manhattan distance: $d(i,j) = |x_{i1}-x_{j1}| + |x_{i2}-x_{j2}| + \\cdots + |x_{ip}-x_{jp}|$<br>\n",
    "Euclidean distance: $d(i,j) = \\sqrt{(x_{i1}-x_{j1})^2 + (x_{i2}-x_{j2})^2 +\\cdots+ (x_{ip}-x_{jp})^2}$ <br>\n",
    "Numpy supports vector mathematical operations in element-wise manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(np.abs(d1-d2)))     # the sum of absolute differences between data points d1 and d2\n",
    "print(np.sqrt(np.sum(np.power((d1-d2),2))))  # the square root of the squared sum of differences between data points d1 and d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have libraries for computing them more conveniently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "print(manhattan_distances([d1,d2]))\n",
    "print(euclidean_distances([d1,d2]))     # Results are displayed as distance matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop rows with some criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with some criteria\n",
    "df.hist('residual sugar')         # draw histogram for the original data\n",
    "idx= df['residual sugar']<=10     # keep the data when the attribute residual sugar is less than or equal to 10, drop others\n",
    "temp_df = df[idx]\n",
    "temp_df.hist('residual sugar')    # draw histogram for the selected data\n",
    "print(df.shape)\n",
    "print(temp_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace with mean or median values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_df = pd.read_csv('./winequality-red_with_noise.csv',sep=';')\n",
    "noise_df.head(10)   # display the first 10 rows of another wine data set with noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_df.isnull().any()          # check whether there is any missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that two columns are now having missing data items.\n",
    "We are going to fill the missing data in the first column with mean value of the \"fixed acidity\", while replace the ones in the second column with median value of \"volatile acidity\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = noise_df['fixed acidity'].mean(skipna=True)        # calcuate the mean value for the attribute fixed acidity\n",
    "v2 = noise_df['volatile acidity'].median(skipna=True)   # calculate the median value for the attribute volatile acidity\n",
    "print(v1,v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'fixed acidity':v1,'volatile acidity':v2}\n",
    "clean_df = noise_df.fillna(value=values)      # fill in the missing value with mean or median\n",
    "clean_df.head(10)\n",
    "# note that fillna just returns a dataframe, the original dataframe has not been changed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.isnull().any()             # check missing value again after filling in mean or median, now clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see how normalization affect performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we drop \"quality\" column and use it as the targets for a multi-class classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  df.drop('quality',1)\n",
    "y = df['quality']   # you need to specify the second parameter, which is direction of axis, starting from 0 \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()     # display the first five rows of the class/label attribute: quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors, linear_model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 5)      # KNN: k-nearest neighbour classification algorithm\n",
    "knn_model_1 = knn.fit(X_train, y_train)\n",
    "print('k-NN accuracy for test set: %f' % knn_model_1.score(X_test, y_test))\n",
    "from sklearn.metrics import classification_report\n",
    "y_true, y_pred = y_test, knn_model_1.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))  # precision, recall, and f1-score are evaluation metrics, the higher, the better\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we have 45.6% of Accuracy by using K-NN classifier. Now, we are using the normalization methods, min-max scaling and z-score scaling, to see how the results are improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()     # do the min-max normalization\n",
    "Xs = min_max_scaler.fit_transform(X)      \n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "Xs_train, Xs_test, y_train, y_test = train_test_split(Xs, y, test_size=0.2, random_state=42)\n",
    "knn_model_2 = knn.fit(Xs_train, y_train)\n",
    "print('k-NN score for test set: %f' % knn_model_2.score(Xs_test, y_test))\n",
    "y_true, y_pred = y_test, knn_model_2.predict(Xs_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is improved by using min-max normalization.\n",
    "Let's see how the z-score normalization goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "Xs = preprocessing.scale(X)     # do the z-score normalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "Xs_train, Xs_test, y_train, y_test = train_test_split(Xs, y, test_size=0.2, random_state=42)\n",
    "knn_model_2 = knn.fit(Xs_train, y_train)\n",
    "print('k-NN score for test set: %f' % knn_model_2.score(Xs_test, y_test))\n",
    "y_true, y_pred = y_test, knn_model_2.predict(Xs_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is further improved. In fact, which normalization method is chosen is totally up to data, can try both. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
